{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Serie 14\n",
    "\n",
    "Completed by Claret Romain, Ménétrey Jämes, Rochat Damien and Sandoz Michaël."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change the number of units and epochs of the LSTM network. Show the configuration that performed the best.\n",
    "\n",
    "The initial result of the training with the batch size of **64**, number of epochs set to **20** and the number of LSTM units set to **1**:\n",
    "\n",
    "- Training correlation coefficient: 0.639540111378689\n",
    "- Test correlation coefficient: 0.6416686449673735\n",
    "\n",
    "![The predicted run with the initial parameters.](img/before-changes-result.png)\n",
    "![The MSE with the initial parameters.](img/before-changes-mse.png)\n",
    "\n",
    "We noticed that the initial results are showing a sign of overfitting, indeed the correlation coefficient on the testing set performs better than on the training set. The batch size is probably too small.\n",
    "\n",
    "The following code has been used to find an optimal number of LSTM units using a systematic approach. While experimenting we noticed a few points:\n",
    "- We used mostly the TPU backend on Google Colab because it's performing faster, about a ratio of **1:4**. Concerning result comparaison from TPU and GPU, we noticed that GPU equivalant results are generally underfit or overfit.\n",
    "- Running the initial code on a TPU backend is providing a different results, which is not overfitting. Indeed, the value for the training correlation coefficient is **0.6252519179188435** and for the testing set **0.6235112426366156**.\n",
    "- We are running each experiment 3 times and keep the best testing reslut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 140\n",
    "NB_EPOCHS = 40\n",
    "NB_UNITS = 20\n",
    "\n",
    "h_train = []\n",
    "h_test = []\n",
    "\n",
    "REPEAT = 3\n",
    "for i in range(1, 2, 1):\n",
    "  start = timer()\n",
    "  for j in range (1,REPEAT+1,1):\n",
    "    print(\"progress \", j, \"/\", REPEAT)\n",
    "    \n",
    "    #BATCH_SIZE = i\n",
    "    #NB_EPOCHS = i\n",
    "    #NB_UNITS = i\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(LSTM(NB_UNITS, input_shape=(TIMESTEPS, len(FEATURES))))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "    history = model.fit(X_train, y_train, epochs=NB_EPOCHS, batch_size=BATCH_SIZE, verbose=0, validation_data=(X_test, y_test))\n",
    "\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    h_train.append(np.corrcoef(y_train.T, y_train_pred.T)[0,1])\n",
    "    h_test.append(np.corrcoef(y_test.T, y_test_pred.T)[0,1])\n",
    "\n",
    "    # Plot the training and testing\n",
    "    pl.plot(history.history['loss'], color='blue')\n",
    "    pl.plot(history.history['val_loss'], color='orange')\n",
    "\n",
    "    #print(history.history['loss'][:-1])\n",
    "  \n",
    "  print(\"BATCH_SIZE = \", BATCH_SIZE)\n",
    "  print(\"NB_EPOCHS = \", NB_EPOCHS)\n",
    "  print(\"NB_UNITS = \", NB_UNITS)\n",
    "  print(\"Best correlation coefficient for training and testing sets:\",h_train[np.argmax(h_test)],h_test[np.argmax(h_test)])\n",
    "  \n",
    "  \n",
    "  pl.xlabel('epochs')\n",
    "  pl.ylabel('mse')\n",
    "  #pl.legend()\n",
    "  pl.grid()\n",
    "  pl.show()\n",
    "  \n",
    "  end = timer()\n",
    "  print(end - start, \"seconds\") # Time in seconds\n",
    "  \n",
    "  h_train = []\n",
    "  h_test = []\n",
    "  \n",
    "  print()\n",
    "  print(\"-----------\")\n",
    "  print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We ran multiple experiments and we were filling an excel spreadsheed to help us optimize the results. We choosed the parameters to be the most performant and the less time consuming. Indeed, we found that using a batch size of **140** and **20** LSTM units was performing well. Concerning the epoch amount, more we are presenting the data, better it performs, however, we observed that **40** performs well for a low learning time, about 1.5 minutes.\n",
    "\n",
    "- TPU Training correlation coefficient: 0.6553012087885829\n",
    "- TPU Test correlation coefficient: 0.6478590610500015\n",
    "\n",
    "![The predicted run with the optimized parameters.](img/after-changes-result.png)\n",
    "\n",
    "![The MSE with the optimized parameters.](img/after-changes-mse.png)\n",
    "\n",
    "\n",
    "About 1 hour later, using **2000** epochs:\n",
    "- TPU Training correlation coefficient: 0.8651456135127776\n",
    "- TPU Test correlation coefficient: 0.8555605818219801\n",
    "\n",
    "![The predicted run with the optimized parameters.](img/2000-epochs-result.png)\n",
    "\n",
    "![The MSE with the optimized parameters.](img/2000-epochs-mse.png)\n",
    "\n",
    "## What is the largest error (speed prediction) you observed? Do you observe that most of those large errors show up for high speeds ? or low speeds? Why?\n",
    "\n",
    "The following code highlights the largest error (MSE):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = np.abs(y_o - y_pred_o[:,0])\n",
    "max_error_index = np.argmax(mse)\n",
    "max_error_value = np.max(mse)\n",
    "\n",
    "\n",
    "print(\"max_error_index:\", max_error_index)\n",
    "print(\"max_error_value:\", max_error_value)\n",
    "print(\"actual speed (at the max):\", y_o[max_error_index])\n",
    "print(\"predicated speed (at the max):\", y_pred_o[max_error_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of the code using the optimized parameters are the following:\n",
    "\n",
    "- max_error_index: 17\n",
    "- max_error_value: 0.4829763010962034\n",
    "- actual speed (at the max): 3.871952636621716\n",
    "- premeditated speed (at the max): 3.3889763\n",
    "\n",
    "The most large errors occur when the actual speed have high picks. The intuitive explanation is because the course first has low speed, thus the LSTM units memorize this result. The second part of the course has an increase of speed and the LSTM units are not yet trained to handle such scenario. If we map the output with the course (presented below), we can see the speed is inversely proportional to the elevation.\n",
    "\n",
    "![The course that has been used for the optimized parameters.](img/course.png)\n",
    "\n",
    "\n",
    "## Compute the correlation between the next speed (model output) and the current speed (model input). Does your LSTM perform better than just using the current speed as a prediction of the next speed ?\n",
    "\n",
    "The correlation is computed using the mean squared error (lower is better). In order to compare the current speed and the next speed, we need to compare the element $y_i$ with $y_{i+1}$. The following code illustrates the comparison:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(A, B):\n",
    "  return (np.square(A - B)).mean()\n",
    "\n",
    "print(mse(y_o[:-1], y_o[1:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output is: 0.13286001427182506. The performance of the LSTM is computed as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mse(y_o, y_pred_o))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output is 0.13739563085444073. Therefore, using the current speed as a prediction of the next speed is better than using the LSTM in this instance.\n",
    "\n",
    "## Using the predicted speeds for a given race, compute the expected time for a race and compute the difference between the real race time and the predicted race time in minutes. Provide the code of the cell that computes this prediction error.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distances(data, races):  \n",
    "  for r in races:\n",
    "    race_df = data.loc[data['race'] == r]\n",
    "    race_np = race_df['distance'].values\n",
    "    race_np = [race_np[i:(i+TIMESTEPS+1)] for i in range(race_np.shape[0] - (TIMESTEPS+2))]\n",
    "    if len(race_np) == 0:\n",
    "      print(\"Warning: not enough values in race\", r)\n",
    "      continue\n",
    "\n",
    "    race_np = np.stack(race_np, axis=0)\n",
    "    \n",
    "  return race_np\n",
    "\n",
    "\n",
    "X, y = create_x_y(dataset, [random_race])\n",
    "X_o, y_o = create_x_y(original_dataset, [random_race])            \n",
    "\n",
    "y_pred_o = model.predict(X) * (max_speed - min_speed) + min_speed \n",
    "\n",
    "x_o_dist = get_distances(dataset, [random_race])\n",
    "\n",
    "time_recorded = 0\n",
    "time_predicted = 0\n",
    "times_recorded = []\n",
    "times_predicted = []\n",
    "dists_recorded = [0]\n",
    "\n",
    "for i in range(1,len(y_o)):\n",
    "  tmp_recorded_dist = x_o_dist[:,0][i]-x_o_dist[:,0][i-1]\n",
    "  dists_recorded.append(tmp_recorded_dist+dists_recorded[-1])\n",
    "    \n",
    "  tmp_recorded_speed = y_o[i]\n",
    "  tmp_recorded_time = tmp_recorded_dist/tmp_recorded_speed\n",
    "  time_recorded += tmp_recorded_time\n",
    "  times_recorded.append(tmp_recorded_time)\n",
    "  \n",
    "  tmp_predicted_speed = y_pred_o[i][0]\n",
    "  tmp_predicted_time = tmp_recorded_dist/tmp_predicted_speed\n",
    "  time_predicted += tmp_predicted_time\n",
    "  times_predicted.append(tmp_predicted_time)\n",
    "  \n",
    "pl.figure(figsize=(14,4))\n",
    "pl.plot(dists_recorded[1:], times_recorded, label='recorded time')\n",
    "pl.plot(dists_recorded[1:], times_predicted, label='predicted time')\n",
    "pl.plot(dists_recorded[1:], np.abs(np.array(times_recorded) - np.array(times_predicted)), label='abs. error')\n",
    "pl.legend()\n",
    "pl.title('race number: ' + str(random_race))\n",
    "pl.xlabel('distance [m]')\n",
    "pl.ylabel('time [s]');\n",
    "  \n",
    "print(\"recorded time:\", time_recorded/60, \"minutes\")\n",
    "print(\"predicted time:\", time_predicted/60, \"minutes\")\n",
    "print(\"abs. time error:\", np.abs(time_recorded - time_predicted)/60, \"minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get the following result:\n",
    "\n",
    "- recorded time: 19.880892867664276 minutes\n",
    "- predicted time: 19.60883281109609 minutes\n",
    "- abs. time error: 0.2720600565681858 minutes\n",
    "\n",
    "![Showing the time based on the speed and distance.](img/2000-epochs-predict-time.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be able to compute the time, we had to compute the distance. Indeed, we computed the distance interval with the last record/predicted speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
